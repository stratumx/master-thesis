\chapter{Сравнение и описание существующих алгоритмов определения и классификации объектов на изображениях}
\section{Теория распознавания образов}

Задача создания саморазвивающихся систем ставилась ещё в 60-е годы, на заре развития вычислительных машин, когда существовала наука под названием <<кибернетика>>, из которой позже сформировалась современная информатика. Кибернетика, являясь, в свою очередь, подразделом математического анализа, изучает закономерности получения, хранения и~обработки информации не только в вычислительных системах, но и~в~сложно устроенных системах вообще, в том числе биологических. Принципы, описываемые данной наукой, напрямую вели к формированию концепции \textit{искусственного интеллекта} -- вычислительной системы искусственного происхождения, склонной к анализу собственных действий и самообучению на его основе. 

Искусственный интеллект -- не только математическая и техническая задача, она дополнительно опирается на принципы функционирования биологических организмов и психологии. Cейчас наука всё ещё не в состоянии точно объяснить работу мозга и теории о природе его функционирования сильно разнятся: от описания химических преобразований до~представления мозга в виде своеобразной <<микросхемы>>, с импульсами и~состояниями~\cite{brain2010, brain2009}. Поэтому, хотя исследования в этой области ведутся уже на~протяжении более чем полувека, создание полноценной самообучающейся системы остаётся недостижимой целью многих специалистов. 

Но, разумеется, нельзя сказать, что всё это время было потрачено впустую. В ходе исследований выделилось большое количество технических новшеств, многие из которых находят применение и в настоящее время. Самые важные из них: нейронные сети, экспертные системы и~системы распознавания образов.

В ходе решения задачи распознавания образов необходимо не только <<увидеть>> объект, но ещё и определить совокупность его \textit{признаков}, классифицировать их и выполнить принятие решения. Признак -- некоторая количественная или качественная характеристика объекта. В природе для живых организмов распознавание образов является самой часто встречающейся задачей на их жизненном пути. Все организмы, имеющие органы чувств, априори способны к анализу поступающей информации и~реагированию в~соответствии с~принятым на его основе решением. 

Однако, человечество не знает точно принципы функционирования сознания, и поэтому невозможно спроектировать искусственные системы распознавания образов так, как это устроено у живых существ, поэтому существующие работы по тематике распознавания образов опираются на~математическое описание системы, часто имеющее вид простой последовательности условий <<если X, то Y>>.

Разумеется, в корне неверно расценивать образы только как визуальные. Если считать образ некой совокупностью данных, то умение извлекать из него необходимую информацию и является целью разработки распознающих систем. Анализируемые данные могут иметь любую структуру: изображение, звуковая дорожка, результат спектрального анализа и~т.\,д. Поэтому любая распознающая система строится, исходя из результатов анализа предметной области и структуризации области данных, с~которыми система будет взаимодействовать.

\begin{figure}[h]
	\centering
	\includegraphics[width=\linewidth]{patt-recogn.png}
	\caption{Общая структура системы распознавания образов}
	\label{fig:pattern_rec}
\end{figure}

Общая структура системы распознавания образов представлена на рисунке \ref{fig:pattern_rec} и состоит из двух общих этапов: разработка системы и~сам процесс распознавания. Как видно, оба этапа тесно связаны между собой и~состоят из последовательных блоков, обозначающих операции проектирования в~укрупнённом виде. На стадии разработки анализируется информация об среде объекта, с которым будет работать будущая система, от количества и степени проработки инофрмации напрямую зависит эффективность работы системы и точность классифицирования объектов. На следующей стадии проводится анализ собранной информации с результатом в виде перечня типовых характеристик объекта, которые будут заложены в~алгоритмы системы. После всего вышеперечисленного проводится выбор подхода к созданию системы и, наконец, разработка подсистемы классификации, где исследуемые характеристики должны быть особым образом упорядочены и структурированы. 

В процессе работы система принимает на вход объект, проводит измерения и выделяет характеристики, сравнивая их с заложенными в её базу знаний на более ранних этапах. Затем, на основе полученных характеристик, происходит присваивание объекта определённому классу или нескольким классам, что, в конечном счёте, является результатом, который можно использовать для решений более глобальных задач.

Любой алгоритм распознавания представляется как некая абстрактная функциональная система F, которая содержит три составляющих:

\begin{equation}
F = \{C, P, R\},
\end{equation}

\noindent{где $C=\{c_i\}, i\in1...N$ -- множество известных классов\,(classes), по которым требуется распределить объекты, $P=\{p_j\}, j\in1...M$ -- множество признаков\,(properties), составляющих описание входного образа, а $R=\{r_k\}, k\in1...K$ -- множество правил\,(rules), которых придерживается система в процессе принятия решения.}

Компоненты подразделяются на две составляющие: информационную\,(множества $C$ и $P$) и методологическую (множество $R$). Способ описания образа во многом зависит от его физической природы, а от способа представления зависят и методы принятия решений, поэтому любая система включает в себя процессы синтеза и анализа образов. Синтез подразумевает формирование описания образа в системе на основе его признаков, а анализ подразумевает процесс принятия решения. Всего выделяют три общих подхода:

\begin{enumerate}
\item \textbf{Метод сравнения с эталоном.} Данный метод является самым простым в реализации, но требует создания базы данных. Суть метода заключается в последовательном сравнении объекта с конечным набором эталонов-отображений, хранящимися в базе данных, где даже для одного объекта может быть множество его интерпретаций и модификаций. Каждый класс сопоставляется со своим набором эталонов $\Omega_k=\{\omega_i, i \in 1...N_k\}$. Разумеется, такой подход работает тем лучше, чем обширней и подробней созданная база данных и иногда попробная проработка может занять огромное количество времени и~ресурсов. Одной из задач искусственного интеллекта при применении данного подхода является расширение базы данных при помощи вычислительных алгоритмов, в соответствии с концепцией самообучения системы.
\item \textbf{Принцип кластеризации.} Данный принцип применяется, когда существует ряд признаков без какой-либо выраженной взаимосвязи друг с другом. Образ в этом случае представляется как n-мерный вектор в пространстве признаков:

\begin{equation}
X: \overrightarrow{x}=\{x_1,\dots,x_n\}
\end{equation}

Каждому классу сопоставляется некоторое множество векторов в пространстве $X$. В результате признаковое пространство разбивается на ряд областей, каждая из которых обозначает один конкретный класс, такие области называются \textit{кластерами} или \textit{таксонами}. Принцип находит своё применение в области обработки больших объёмов количественных данных.
\item \textbf{Принцип общности свойств.} Данный принцип используется, если конечное число образов каждого класса слишком велико для получения надёжного описания эталонов, поэтому используется методика выявления отличительных особенностей класса. Образ обычно хранится в виде структуры или функции, а процесс распознавания заключается в выявлении необходимых свойств образа и последующем его сравнении со схемой конкретного класса.
\item \textbf{Искусственная нейронная сеть.} Данный метод предполагает, что существует большое количество примеров решений задачи распознавания, на которое опирается алгоритм в процессе отнесения к классу. В общем случае речь идёт о задаче обучения распознавания образов, где требуется выявить закономерность классификации объектов, основываясь на имеющейся выборке~\cite{vapnik}. Задача сводится к поиску среди множества зависимостей $F(x, \alpha)$ той, для которой вероятность классификации, отличной от представленной на входе, была бы минимальной:

\begin{equation}
min(I(\alpha))=\sum_{\omega=0,1}\int (\omega-F(x, \alpha))^2 \rho(\omega|x)\rho(x)dx,
\end{equation}

где $I(\alpha)$ -- функционал вида:

\begin{equation}
I(\alpha)=\int_{X, \omega} (\omega-F(x, \alpha))^2 \rho(x, \omega)dxd\omega,
\end{equation}

а функция $\rho(x, \omega)=\rho(\omega|x)\rho(x)$ -- совместная плотность пар $x, \omega$ в пространстве $X\omega$.

\end{enumerate}

\section{Задача классификации объектов}

Основой системы распознавания является классификация. Под классификацией обычно понимается разбиение ряда объектов реального или виртуального мира по общим характеристикам. Как известно, классификация основывается на прецедентах, то есть, на объектах, правильная классификация которых известна. Прецеденты обычно выступают в роли образца при решении задачи~\cite{padun2014}. Выделяют три класса характеристик-признаков:

\begin{enumerate}
\item \textbf{Качественные характеристики.} Описывают качества объекта: размер, цвет, положение и~т.\,д. Они обычно описываются лингвистическими переменными при помощи методов теории нечётких множеств.
\item \textbf{Физические характеристики.} Они представляют собой результаты измерений или показания датчиков: плотность, температура и~т.\,д. Этот класс характеристик обычно описывается и обрабатывается как элементы векторного пространства.
\item \textbf{Структурные характеристики.} Характерны для сложных объектов. Для их описания прибегают к формальным языкам, к примеру, к теории графов.
\end{enumerate}

Предположим, существует некое множество образов $O=\{o_1,\dots, o_n\}$. У каждого объекта из множества существует пространство признаков и,~как правило, оно является конечным. Пусть у объекта существует три характеристики: $x_1, x_2$ и $x_3$, каждая из которых варьируется в пределах множества вариантов. То есть, множество описывается как:

\begin{equation}
X_i=\{{x_j}_1, ..., {x_j}_n\}, j \in \{1,2,3\},
\end{equation}

\noindent{где $n$ -- это количество конкретных видов каждого признака, а~$X_i$ -- множество признаков конкретного объекта $o_i$. В таком случае каждый объект $o_i$ в данной нотации будет описываться кортежем из значений множества признаков:}

\begin{equation}
o_i = \langle{x_1}_i, {x_2}_i, {x_3}_i\rangle
\label{eq:tuple}
\end{equation}

Задача системы распознавания состоит в том, чтобы разбить исходное множество $O$ на подмножества, которые и будут являться классами. Обычно число классов конечно, но в общем виде их может быть бесконечно много. Для проведения разбиения необходимо составить выборку из множества вариантов сочетаний признаков с конечными результатами (\textit{обучающую выборку}) и с вводом так называемого \textit{решающего правила}\footnote{Реш\'ающее пр\'авило, классифик\'атор или индик\'аторная ф\'ункция -- правило отнесения образа к какому-либо классу, исходя из его вектора признаков.} $a(o_i): \{{x_1}_i, {x_2}_i, {x_3}_i\} \to Y$, где $Y=\{y_1,\dots, y_m\}$. Задача алгоритма -- используя решающее правило, соотнести объект с определённым классом из перечня $C=\{c_i\}, i\in1...N$, то есть, поставить объекту $o_i$ метку $y_i$ о соответствии объекта классу $c_i$~\cite{mestetsky}.

У каждого решающего правила  $a(o_i)$ существует понятие качества, определённого как вероятность отнесения объекта к различным классам. Данную характеристику формально можно представить в виде:

\begin{equation}
I(a)=\sum_{i=0}^{p-1}\int \Theta(a(O_i)-\omega_i) \rho(\omega_i|o_i)\rho(o_i)do_i,
\end{equation}

\noindent{где:}

\begin{equation}
\Theta(z) = \left\{
\begin{array}{ll}
0, & \textrm{если } z = 0\textrm{,}\\
1, & \textrm{если } z \ne 0.
\end{array} \right.
\end{equation}

Наиболее общей постановкой задачи классификации является вероятностная постановка, поскольку в подавляющем большинстве случаев приходится иметь дело со степенью неопределённости вектора признаков объекта. Другими словами, вектор признаков будет иметь вид многомерной случайной величины $\xi$. Неопределённость может иметь вероятностный характер и в этом случае множество пар обучающей выборки <<объект-класс>> будет называться \textit{вероятностным пространством} с некой вероятностной мерой $P$. Появление объекта $o_i$ будет случайным событием, которое описывается с помощью законов распределения вероятностей многомерной случайной величины. Задача распознавания сводится к определению на основе обучающей выборки вероятностных характеристик конкретной среды. К вероятностым характеристикам относятся: 

\begin{itemize}
\item[$-$]функция плотности распределения вероятностей $f_{\xi}(o_i)$;
\item[$-$]условная вероятность принадлежности объекта имеющимся классам $p(c_i|o_i^0)$;
\item[$-$]вероятность появления новых классов $p_i=p(c_i)$;
\item[$-$]функция условной плотности распределения вероятностей объектов внутри классов $f_i(x)=f_\xi(x|c_i)$.
\end{itemize}

Перечисленные выше вероятностные характеристики связаны отношениями. Если считать, что классы образуют полную группу событий, т.\,е. $c_i \cap c_j = \varnothing, i \ne j$, а сумма вероятностей всех классов равна единице, то:

\begin{equation}
f_{\xi}(o_i)=\sum_{k=1}^{m}p_k f_k (o_i)
\label{eq:fullver}
\end{equation}

\begin{equation}
p(c_i|o_i)=\frac{p_i f_i (o_i)}{f_\xi (o_i)}
\label{eq:bayes}
\end{equation}

Формула \ref{eq:fullver} носит название \textit{формулы полной вероятности}, а формула \ref{eq:bayes} -- \textit{формула Байеса\footnote{Б\'айес, Т\'омас\,(Thomas Bayes)\,(1702--1761) -- английский математик.}}.

В случае, если вероятностные характеристики известны, то в байесовской классификации задача сводится к тому, что при разбиении пространства $R_n$ на некоторое количество непересекающихся областей необходимо добиться минимизации средней ошибки $Q$ и средних потерь $R$ от случая неправильной классификации объекта:

\begin{equation}
Q=\sum_{k=1}^{m} \int_{R_n/X_k} p(c_i|o_i) f(o_i)do_i
\label{eq:classerror}
\end{equation}

\begin{equation}
R=\sum_{i-1}^{m}  \int_{X_i} R(c_i|o_i) f(o_i)do_i
\end{equation}

Ошибка $Q$ складывается из суммы вероятностей отнесений вектора $o_i$ к ошибочным классам. Другими словами, пусть имеется три непересекающиеся области пространства $R_n$: $X_1$, $X_2$ и $X_3$, а множество классов содержит три элемента $C=\{c_1, c_2, c_3\}$. Тогда средняя ошибка $Q_1$ для области $X_1$ будет равна:

\begin{equation}
Q_1=\int_{X_1} p(c_2|o_i) f(o_i)do_i + \int_{X_1} p(c_3|o_i) f(o_i)do_i,
\label{eq:q1error}
\end{equation}

\noindent{то есть, сумме ошибок отнесения вектора $o_i$ к классам, соответственно, $c_2$ и $c_3$, тогда как он принадлежит классу $c_1$. Соответственно определяются средние ошибки $Q_2$ и $Q_3$ для областей $X_2$ и $X_3$. Средняя ошибка $Q$ будет минимальна, если:}

\begin{equation}
X_i=\{x \in c_i: p_i f_i (o_i) > p_j f_j (o_i)\}, i \ne j
\end{equation}

Что касается потерь, то они также будут равны сумме потерь для каждого класса из множества $C$. Для случая из трёх классов:

\begin{equation}
\begin{gathered}
R=\int_{X_1} (r_{11} p_1 f_1(o_i)+(r_{21} p_2 f_2(o_i)+(r_{31} p_3 f_3(o_i))do_i +\\
+ \int_{X_2} (r_{12} p_1 f_1(o_i)+(r_{22} p_2 f_2(o_i)+(r_{32} p_3 f_3(o_i))do_i +\\
+ \int_{X_3} (r_{13} p_1 f_1(o_i)+(r_{23} p_2 f_2(o_i)+(r_{33} p_3 f_3(o_i))do_i
\end{gathered}
\end{equation}

\section{Обзор существующих алгоритмов и методик обработки изображений}

Машинное зрение, как очевидно из названия, имеет дело с изображениями, чаще всего растрового типа, а поступление на вход алгоритма изображения носит характер случайного события. Важно заметить, что задача распознавания и классификации образов по сей день не решена в~полном объёме, несмотря на труды математиков всей второй половины XX века, и поэтому построение надёжной системы -- вопрос далёкого будущего. Тем~не~менее, существует масса методик, позволяющих решить поставленную задачу с результатом, приближённым к идеальному, и степень приближенности сильно зависит от условий задачи.

При проектировании систем распознавания изображений, важно учитывать не только логику алгоритма обработки, но и технические характеристики используемого оборудования и среды, где это техническое оборудование будет работать. Не существует универсального алгоритма, который одинаково хорошо работал бы в любых условиях и с любыми данными, поэтому для выбора алгоритма необходимо сперва ознакомиться с условиями рабочей среды, воздействиями среды на работу технических средств и~организацией передачи изображений на микроконтроллер с программой-обработчиком. На качество получаемого цифрового изображения напрямую влияет множество факторов, которые можно условно разбить на четыре группы:

\begin{enumerate}
\item \textit{Факторы, непосредственно связанные с композицией и типом изображения.} Это масштаб, фон, угол поворота объекта и~т.\,д. Они напрямую зависят от качества принимающего оборудования и учёта технических характеристик оптических и разрешающих средств\,(например, фокусное расстояние объектива камеры, разрешение матрицы или посторонние тела на линзе).
\item \textit{Факторы, вызванные условиями рабочего пространства}, то есть, то, что обычно можно видеть или ощущать даже невооружённым взглядом. К ним относятся такие параметры, как освещённость, запылённость, механические вибрации. В~этом случае необходимо учитывать возможность дооснащения приёмопередающего устройства дополнительным освещением, виброгасящим или гиростабилизированным подвесом и другими защитными средствами.
\item \textit{Факторы, вызванные полями наведения.} К ним относятся помехи, обусловленные наличием большого количества электроприборов в непосредственной близости от оборудования, электростатические или радиационные возмущения. Опять же требуют дополнительного дооснащения оборудования средствами защиты.
\item \textit{Факторы, вызванные особенностями каналов передачи данных.} К ним относятся потери при передаче, которые разнятся при использовании разных каналов связи. Необходимо проанализиовать допустимую меру искажения изображения и выбирать подходящий канал связи.
\end{enumerate}

Обрабатывающие алгоритмы можно разделить по классам, согласно выполняемым ими функциям. Существует три основных категории алгоритмов: фильтрационные, обрабатывающие и обучающие~\cite{jahne2005, gonzalez2007}.

\subsection{Алгоритмы фильтрации изображений}

Главная задача алгоритмов фильтрации состоит в том, чтобы на исходном изображении выделить интересующие области, не прибегая к анализу изображения. Фильтры обычно применяются одинаково ко всем пикселям изображения, при этом области, прошедшие фильтрацию можно назвать областями с особыми свойствами. Чаще всего к ним прибегают для решения относительно несложных задач с входными изображениями общего типа. Существует несколько классов фильтров, среди которых можно назвать следующие:

\begin{enumerate}
\item \textbf{Пороговая бинаризация.} Является самым простым видом преобразования, суть которого состоит примерно в следующем: на исходном изображении выбирается определённое значение яркости пикселя (или значение цвета, если алгоритм имеет дело с изображением в~RGB), а затем каждый пиксель, чья яркость выше заданной, получает максимум яркости\,(то есть, 255), а остальные, соответственно, минимум\,(0). Данный метод подходит для простых задач, к примеру, выделения объектов на однотонном фоне.

Порог может задаваться вручную, но в большинстве алгоритмов реализуется автоматическое его определение, что расширяет область поддающихся фильтру изображений. В качестве значения порога может выбираться среднее значение яркости пикселей из встречающихся на изображении или наибольший пик гистограммы.
\item \textbf{Классические фильтры.} К ним относятся преобразования Фурье, фильтры высоких и низких частот(ФВЧ и ФНЧ). 

Под преобразованием Фурье обычно понимают \textit{дискретное преобразование Фурье (ДПФ)}, а это, в свою очередь, есть аналог непрерывного преобразования Фурье для дискретного сигнала, содержащего $N$ отсчётов~\cite{fourier1988}. Пусть сигнал имеет значения $a_n, n=0,\dots,N-1$, тогда ДПФ имеет вид:

\begin{equation}
A_k=\sum^{N-1}_{n=0}a_ne^{-\frac{2\pi i}{N}kn}, k\in\{0;N-1\}
\end{equation}

Однако, ДПФ изначально разрабатывался для анализа звуковых частотных сигналов, то есть, он может работать лишь с одномерными массивами. Для анализа изображений применяется двумерное ДПФ:

\begin{equation}
A_{uw}=\frac{1}{M \cdot N} \sum^{N-1}_{n=0} \sum^{M-1}_{m=0} a_ne^{-2 \pi j [\frac{mu}{M}-\frac{nw}{N}]}, m,n\in\{0;N-1\}
\end{equation}

Данный вид преобразования проводит ДПФ последовательно по всем строкам изображения и поэтому он весьма ресурсоёмок.

Что касается ФВЧ и ФНЧ, то их реализация примерно одинакова. Для каждого пикселя изображения выбирается окно, которое умножается на маску соответствующего фильтра. Различают фильтр Гаусса\,(для низких частот)~\cite{haddad1991} и~фильтр Габора\,(для высоких)~\cite{gabor1994}.

\item \textbf{Вейвлет-преобразование.} Анализ изображения с применением математической функции. График функции имеет волнообразную форму, откуда и появилось название <<вейвлет>>\footnote{От англ wave -- волн\'а.}. Суть метода заключается в проведении свёртки\footnote{Свёртка -- математическое преобразование над двумя функциями, которое в общем виде можно определить как результирующую функцию, отражающую меру схожести двух исходных функций.} вейвлет-функции с сигналом. Метод также предназначен для обработки звуковых волн, поэтому в случае изображений проводится свёртка части изображения с паттерном. Существует ряд классических вейвлет-функций, использующихся для анализа изображений: вейвлет Хаара~\cite{haar1910}, вейвлет Морле~\cite{morlet2012} и другие.

\item \textbf{Фильтрация функций.} Она позволяет найти на изображении простую математическую функцию. Для каждой точки изображения отрисовывается множество порождающих функций. Наиболее классический случай -- преобразование Хафа~\cite{ballard1981}. Алгоритм преобразования Хафа для прямых использует специальный массив (аккумулятор) для определения присутствия прямой $y=kx+b$. Для каждой точки изображения $(x;y)$ отрисовывается множество точек $(k;b)$, для которых равенство $y=kx+b$ верно.

Преобразования Хафа позволяют находить на изображениях любые функции, которые можно описать параметрически: окружность, синусоиду, эллипс и т.\,д. Но алгоритм Хафа нельзя назвать надёжным из-за того, что он имеет довольно низкую скорость работы и высокую чувствительность к бинаризации.

\item \textbf{Фильтрация контуров.} Данный тип фильтра применяется для~случая, когда необходимо перейти от работы с изображением к работе с объектами на нём. Существует ряд контурных фильтров: Собеля~\cite{sobel2009}, Лапласа~\cite{laplace2009} или Превитта~\cite{prewitt2010}, но чаще всего имеют дело с фильтром Кэнни~\cite{canny1986}, как наиболее эффективным. Алгоритм делится на несколько последовательных шагов:

\textit{Сглаживание} убирает шум при помощи размытия исходного изображения. Для этого оператор Кэнни использует фильтр, приближенный к~первой производной гауссианы $\sigma=1.4$:

\begin{equation}
B=\frac{1}{159}
\begin{bmatrix} 
2 & 4 & 5 & 4 & 2 \\ 
4 & 9 & 12 & 9 & 4 \\
5 & 12 & 15 & 12 & 5 \\
4 & 9 & 12 & 9 & 4 \\
2 & 4 & 5 & 4 & 2 \\ 
\end{bmatrix}
\cdot A
\end{equation}

\textit{Поиск градиентов} выполняет поиск областей, где значение градиента максимально. Алгоритм Кэнни использует 4 фильтра в разных направлениях:

\begin{equation}
G=\sqrt[]{G_x^2+G_y^2}
\end{equation}

\begin{equation}
\Theta=\arctg(\frac{G_y}{G_x})
\end{equation}

\textit{Подавление немаксимумов} или \textit{Двойная пороговая фильтрация} для того, чтобы отображались только границы\,(локальные максимумы).

\textit{Трассировка области неоднозначности} для итогового уточнения границ, выполняется путём подавления их краёв. 
\end{enumerate}

Существуют и другие, более экзотические версии фильтрационных алгоритмов (курвлет-преобразования\footnote{От англ. curve -- крив\'ая.}, итерационные фильтры и др.), однако они предназначены для совсем специфических задач и рассматривать их нет смысла.

\subsection{Алгоритмы логической обработки изображений}

В предыдущем разделе были рассмотрены фильтрационные методы, которые позволяют получить данные из входного изображения без анализа. Но в некоторых задачах недостаточно получить данные, для использования их нужно особым образом обработать. Далее приводится несколько типов обрабатывающих алгоритмов.

\begin{enumerate}
\item \textbf{Математическая морфология.} К ним относятся простейшие операции по наращиванию и эрозии изображений в бинарном виде. Они применяются, в основном, для выравнивания контуров и снижению шума на изображении.

Исходными данными для алгоритма служат исходное бинарное изображение и некий структурный элемент. В роли последнего, как правило, выступает геометрическая фигура в двоичном отображении, как показано на рисунке \ref{fig:str-el}. На каждом элементе выделяется начальная точка, которая может быть любой точкой изображения. Результирующий кадр заполняется элементами со значением~<<1>>, формируя белое изображение, а затем каждому пикселю проводится зондирование, т.\,е. совмещение пикселя и~структурного элемента так, чтобы начальная точка и пиксель совпали. После чего выполняется проверка некоего условия на соответствие пикселей и, в случае его выполнения, пикселю присваивается значение <<0>>. Таким образом может выполняться наращивание или сужение\,(эрозия) контура, в зависимости от поставленного условия.

\begin{figure}[t]
	\centering
	\includegraphics[width=0.7\linewidth]{structure-elements.png}
	\caption{Основные структурные элементы: прямоугольник, круг и кольцо}
	\label{fig:str-el}
\end{figure}

\item \textbf{Контурный анализ.} Позволяет получать контуры из бинарных изображений. Наиболее распространённый алгоритм этого типа -- алгоритм жука~\cite{andreev2014}. Данный метод получил название по схожести с поведением жука, который обходит препятствие. 

Порядок действий состоит в следующем. Некая активная точка, начиная свой путь с пикселя со значением <<1>>, двигается по пикселям вперёд. Если она достигает пикселя со значением <<0>>, то направление движения изменяется и точка начинает идти влево. Если следующий пиксель тоже имеет значение <<0>>, то снова происходит поворот налево, а если <<1>>, то направо\,(рис. \ref{fig:bug-alg}). Алгоритм выполняется до достижения активной точкой своей исходной позиции, а местоположение границы определяется декартовыми координатами переходов с одного значения на другое. К сожалению, применение данного метода также требует наличия идеальных качественных характеристик для входного изображения.

\begin{figure}[t]
	\centering
	\includegraphics[width=0.55\linewidth]{bug_alg.pdf}
	\caption{Прослеживание контура алгоритмом жука}
	\label{fig:bug-alg}
\end{figure}

\item \textbf{Метод особых точек.} Данный метод предназначен для работы сериями кадров, поскольку использует в своей основе методы выделения точек с уникальными характеристиками объекта для сопоставления с похожими классами. Методов выделения точек существует довольно много и их можно разделить по сложности реализации.

\textit{Выделение точек, стабильных в течение короткого времени}. Чаще всего это или локальные максимумы изображения, области углов или точки максимумов дисперсии. Методы применяются для сведения нескольких кадров видео в один.

\textit{Выделение точек, стабильных при смене освещения и небольших движениях объекта.} Методами могут служить некоторые из вейвлетов, поиск бликов или специфических функций. Применяется в обучающих алгоритмах для последующей классификации.

\textit{Выделение точек, стабильных всё время.} Достаточно сложные алгоритмы, к которым относятся SURF~\cite{surf2008} и SIFT~\cite{sift2004}.

Метод SURF предназначен для поиска особых точек и созданиях их дескрипторов\footnote{Дескр\'ипторы -- описательные элементы, инвариантные к повороту и изменению масштаба.} и основан на использовании детерминанта матрицы Гессе\,(гессиана), который в точках максимального градиента достигает экстремума. Для двумерной функции детерминант имеет вид:

\begin{equation}
H(f{x,y})=
\begin{bmatrix} 
\frac{\partial^2 f}{\partial x^2} & \frac{\partial^2 f}{\partial x \partial y} \\
\frac{\partial^2 f}{\partial x \partial y} & \frac{\partial^2 f}{\partial y^2}
\end{bmatrix}
\end{equation}

\begin{equation}
det(H)=\frac{\partial^2 f}{\partial x^2} \frac{\partial^2 f}{\partial y^2} - \left(\frac{\partial^2 f}{\partial x \partial y} \right)^2
\end{equation}

Метод SURF использует для нахождения гессианов фильтры разного масштаба. Для каждой точки изображения считается градиент\,(через фильтры Хаара) и масштаб. После нахождения особых точек метод формирует их дескрипторы, имеющие вид массива из 64\,(иногда 128) чисел, отражающих флуктуации\footnote{Флукту\'ация -- любое случайное отклонение от какой-либо величины.} градиента вокруг ключевой точки.

Алгоритм SIFT схож с алгоритмом SURF в общей методике расчёта. В методе SIFT детектирование особых точек выполняется через формирование пирамиды гауссианов и разностей гауссианов (\ref{eq:gaussian}). Гауссиан имеет вид размытого при помощи Гауссова шума исходного изображения.

\begin{equation}
L(x,y,\sigma)=G(x,y,\sigma) * I(x,y),
\label{eq:gaussian}
\end{equation}

где $L$ -- значение гауссиана в точке $(x;y)$, $G$ -- гауссово ядро\footnote{Ядр\'о\,(матем.) -- некоторая функция $F(x,y)$, представимая в виде скалярного произведения в некотором пространстве\cite{sokolov2013}. }, $\sigma$ -- радиус размытия, $I$ -- исходное изображение, * -- функция свёртки. Разность гауссианов -- это изображение, полученное через попиксельное вычитание гауссиана исходного изображения из гауссиана с другим радиусом размытия. Точка считается особой, если она является локальным экстремумом разности гауссианов.

На следующем шаге алгоритма выбранные ранее особые точки уточняются при помощи аппроксимирования функции разности гауссианов\,(DoGF\footnote{Difference of Gaussian Function}) через многочлен Тейлора второго порядка:

\begin{equation}
D(x)=D+\frac{\partial D^T}{\partial x}x+ \frac{x^T}{2}\frac{\partial^2 D}{\partial x^2}x,
\label{eq:taylor}
\end{equation}

где $D$ -- DoGF, $X=(x,y,\sigma)$ -- вектор смещения, первая производная DoGF -- градиент, вторая производная DoGF -- матрица Гессе. Результатом уточнения является вычисление отклонения расчётного экстремума от реального. Далее точка подвергается ещё нескольким проверкам, в том числе на определение её направления.

Наконец, для найденной особой точки вычисляется дескриптор. В методе SIFT им является вектор, направление которого также расчитывается на ближайшем по масштабу ключевой точки гауссиане. Перед расчётом дескриптора окно ключевой точки поворачивают на угол её направления, найденный на прошлом этапе, чем достигается инвариантность относительно поворота.

Как можно заметить, алгоритмы SURF и SIFT являются достаточно трудоёмкими для реализации и требуют больших вычислительных мощностей. Кроме того, они охраняются патентом, что не даёт права использовать их в коммерческих проектах, без получения соответствующего разрешения.

\end{enumerate}

\subsection{Алгоритмы обучения}

Алгоритмы обучения не работают с изображениями напрямую, но позволяют принимать решения относительно имеющихся объектов. В 80\,\% суть работы алгоритма реализует описанное в разделе 2.2, поэтому останавливаться на этом подробно нет смысла. Автор лишь хочет отметить, что алгоритмов обучения существует огромное количество и среди имеющихся можно отметить, например, K-means~\cite{kmeans2003}, AdaBoost~\cite{adaboost2009} и Support Vector Machine\,(SVM)~\cite{svm1995}.

\textit{K-means} -- достаточно простой обучающий алгоритм кластеризации, известный ещё с 50-х годов. Его действием является минимизация суммарного квадратичного отклонения точек кластеров от их центров.

\textit{AdaBoost}\,(Adaptive boosting) -- популярный алгоритм усиления классификаторов, который используется в сочетании с другими алгоритмами для усиления их эффективности. Обычно он используется при проведении бинарной классификации.

\textit{SVM}\,(метод опорных векторов) -- довольно мощный классификатор, работающий аналогично AdaBoost, но обучающий алгоритм сложнее и требует выбора правильного ядра. Идея заключается в переводе исходных векторов в пространство с более высокой размерностью и поиск разделяющей гиперплоскости с наибольшим зазором в данном пространстве.

\subsection{Критерии выбора методик обработки}

В ходе анализа имеющихся методов распознавания объектов на изображении является очевидным, что далеко не все из них могут использоваться при решении поставленной задачи. Какие-то требуют больших вычислительных мощностей, какие-то тратят слишком много времени на выполнение. Исходя из описания состава технических средств, формирующих компонент машинного зрения\, (состав и характеристики оборудования описаны в разделе \ref{razd3-2} данной выпускной квалификационной работы), следует отметить, что для ускорения расчётов и обеспечения обработки в реальном времени необходимо выбрать наиболее оптимизированные из них. С другой стороны, хотя задача обеспечения высокой точности в рамках данной работы не стоит, в перспективе будет необходимо рассмотреть этот вопрос, поэтому выбор наиболее быстрого алгоритма в ущерб точности и надёжности не является наилучшим.

Поскольку ни один алгоритм не подходит для выполнения поставленной задачи на 100\,\%, логичным является сочетание двух-трёх разных методов обработки, направленных на разные задачи. Реализованный алгоритм описан в следующем разделе.

\section{Описание применяемого алгоритма работы}

Очевидно, что при разработке обрабатывающей программы необходимо изучить условия, в которых она будет работать. В разработке алгоритма распознавания меток учитывались следующие условия работы модуля:

\begin{enumerate}
\item Процесс обработки кадра видео выполняется на микрокомпьютере Odroid, который обладает сравнительно невысокими техническими характеристиками, и поэтому необходимо избегать проведения лишних вычислений.
\item Метка имеет вид круглого чёрно-белого изображения, поэтому надобность в обработке цветных изображений отсутствует.
\item Метка, как правило, самый высококонтрастный объект в кадре.
\end{enumerate}

Приближенный порядок действия обрабатывающего алгоритма состоит из четырёх общих этапов, как показано на рисунке \ref{fig:main-algor}.

\begin{figure}[t]
	\centering
	\includegraphics[width=0.9\linewidth]{algor.pdf}
	\caption{Основные стадии используемого алгоритма обработки}
	\label{fig:main-algor}
\end{figure}

\textbf{I этап.} Приём на вход потокового видео. Входной поток представлен в виде набора кадров (изображений), поступающих на обработчик с некоторой частотой. Для оптимизации расчётов каждое изображение переводится в полутоновый формат по формуле:

\begin{equation}
G=\frac{R+G+B}{3},
\end{equation}

где $G$ -- значение яркости пикселя в полутоновом изображении в диапазоне \{0--225\}, $R, G$ и $B$ -- значения яркости, соответственно, красной, зелёной и синей составляющих пикселя исходного изображения.

\textbf{II этап.} На данном этапе входное изображение проходит обработку детектирования границ методов градиентной фильтрации. В алгоритме применяется фильтр Собеля, уступающий фильтру Кэнни в качестве выходного результата, но работающий на порядок быстрее из-за отсутствия уточняющих вычислений.

\textbf{III этап.} Пороговая бинаризация. Для дальнейшей простоты определения границ выполняется бинаризация изображения, после чего изображение принимает вид двумерного массива из нулей и единиц.

\textbf{IV этап.} Контурный анализ. На этом этапе изображение анализируется с точки зрения закрытых контуров, найденный контур подразумевает под собой метку. Выполняется проверка на закрытость контура, таким образом отсеиваются случайные флуктуации на изображении и метки, частично ушедшие за границу кадра.

\begin{figure}[t]
	\centering
	\includegraphics[width=0.5\linewidth]{alg-result.png}
	\caption{Пример работы обрабатывающего алгоритма}
	\label{fig:result}
\end{figure}

Результат работы алгоритма представлен на рисунке \ref{fig:result}, но следует оговориться, что данное изображение иллюстрирует отладочную работу алгоритма. В ходе отладок в качестве приёмного оборудования использовалась веб-камера с разрешающей матрицей 0,3 MPx\,(размер кадра $640\times480$ точек). Кроме того, в качестве выходного кадра используется изменённое оригинальное изображение, тогда как в работе платформы демонстрация входного кадра при определении метки не осуществляется\,(за исключением трансляции видеопотока на пользовательский виджет). Текст программы на языке Python представлен в приложении \ref{app:a}.

\section{Выводы ко второй главе}

\begin{enumerate}
\item Приведено описание и постановка задачи классификации объектов, описаны имеющиеся методы. Определён предмет распознавания образов и его роль в исследованиях.
\item Описаны и проанализированы методы обработки изображений, проведена их классификация в соответствии с проводимой функцией. Каждый метод подходит под свой класс задач реализации и в сложных задачах может потребоваться их комбинация.
\item Приведена структура обрабатывающего алгоритма с описанием основных этапов обработки, исходя из рассмотренных условий работы оборудования.
\end{enumerate}